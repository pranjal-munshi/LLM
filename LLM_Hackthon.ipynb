{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ-Kb6H32mRy",
        "outputId": "ee84bde8-d774-42fe-eb4a-f569cbefd128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "# /content/drive/MyDrive/LLM_DATASET.zip\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/LLM_DATASET.zip\"\n",
        "extract_path = \"/content/LLM_DATASET\"\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU6vgtnpqgAJ",
        "outputId": "dd2d83cc-1f68-47f3-cf31-b56a5c855ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required dependencies...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['pip', 'install', 'PyPDF2', 'SpeechRecognition', 'pydub', 'moviepy', 'python-pptx', 'Pillow', 'PyMuPDF'], returncode=0)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Installing required dependencies...\")\n",
        "import subprocess\n",
        "subprocess.run([\"pip\", \"install\", \"PyPDF2\", \"SpeechRecognition\", \"pydub\", \"moviepy\",\"python-pptx\", \"Pillow\", \"PyMuPDF\"], check=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51RIDOgv9P-s",
        "outputId": "2363fa9e-b849-4dd7-c8c0-6da611dcff59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required dependencies...\n",
            "Installing poppler-utils for better PDF image extraction...\n",
            "poppler-utils installed successfully.\n",
            "Installing Whisper...\n",
            "Whisper installed successfully.\n",
            "FFmpeg is already installed.\n",
            "Processing files from /content/LLM_DATASET/LLM_DATASET/BST\n",
            "Processing PowerPoint: Class2_Unit3_Tree_BST_DynamicInsert.pptx\n",
            "Extracted 13 images from /content/LLM_DATASET/LLM_DATASET/BST/Class2_Unit3_Tree_BST_DynamicInsert.pptx\n",
            "Extracted 13 images from Class2_Unit3_Tree_BST_DynamicInsert.pptx\n",
            "Processing PowerPoint: Class4_Unit3_Trees_BST_ArrayInsert.pptx\n",
            "Extracted 21 images from /content/LLM_DATASET/LLM_DATASET/BST/Class4_Unit3_Trees_BST_ArrayInsert.pptx\n",
            "Extracted 21 images from Class4_Unit3_Trees_BST_ArrayInsert.pptx\n",
            "Processing PowerPoint: Class3_Unit3_Trees_BSTDeletion.pptx\n",
            "Extracted 14 images from /content/LLM_DATASET/LLM_DATASET/BST/Class3_Unit3_Trees_BSTDeletion.pptx\n",
            "Extracted 14 images from Class3_Unit3_Trees_BSTDeletion.pptx\n",
            "Processing complete. Results saved to /content/output_folder\n",
            "Extraction summary saved to /content/output_folder/extraction_results.json\n",
            "Done! Extracted texts, images, and transcriptions saved to /content/output_folder\n",
            "Note: Video frame extraction is disabled (frames_per_second=0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import PyPDF2\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from moviepy.editor import VideoFileClip\n",
        "import shutil\n",
        "import tempfile\n",
        "import json\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text from the PDF\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            num_pages = len(reader.pages)\n",
        "\n",
        "            for page_num in range(num_pages):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text() + \"\\n\\n\"\n",
        "\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting text from {pdf_path}: {str(e)}\"\n",
        "\n",
        "def extract_pdf_images(pdf_path, output_folder):\n",
        "    \"\"\"\n",
        "    Extract images from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file\n",
        "        output_folder (str): Path to save the extracted images\n",
        "\n",
        "    Returns:\n",
        "        list: Paths to extracted images\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create temp folder to store the extracted images\n",
        "        pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "        image_folder = os.path.join(output_folder, f\"{pdf_name}_images\")\n",
        "        os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "        # Use pdfimages (from poppler-utils) to extract images\n",
        "        # This is more reliable than PyPDF2 for image extraction\n",
        "        try:\n",
        "            subprocess.run([\"pdfimages\", \"-j\", pdf_path, os.path.join(image_folder, \"img\")],\n",
        "                           check=True, stderr=subprocess.DEVNULL)\n",
        "            print(f\"Extracted images from {pdf_path} using pdfimages\")\n",
        "        except:\n",
        "            # If pdfimages fails, try PyMuPDF (fitz) as a fallback\n",
        "            print(\"pdfimages not available, trying PyMuPDF...\")\n",
        "            try:\n",
        "                import fitz  # PyMuPDF\n",
        "\n",
        "                doc = fitz.open(pdf_path)\n",
        "                image_count = 0\n",
        "\n",
        "                for page_num, page in enumerate(doc):\n",
        "                    image_list = page.get_images(full=True)\n",
        "\n",
        "                    for img_index, img in enumerate(image_list):\n",
        "                        xref = img[0]\n",
        "                        base_image = doc.extract_image(xref)\n",
        "                        image_bytes = base_image[\"image\"]\n",
        "                        image_ext = base_image[\"ext\"]\n",
        "\n",
        "                        with open(os.path.join(image_folder, f\"img_{page_num+1}_{img_index+1}.{image_ext}\"), \"wb\") as img_file:\n",
        "                            img_file.write(image_bytes)\n",
        "                            image_count += 1\n",
        "\n",
        "                print(f\"Extracted {image_count} images from {pdf_path} using PyMuPDF\")\n",
        "            except ImportError:\n",
        "                print(\"PyMuPDF not installed. Install with: pip install PyMuPDF\")\n",
        "                return []\n",
        "\n",
        "        # Return the list of images\n",
        "        images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))]\n",
        "\n",
        "        return images\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting images from {pdf_path}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def convert_video_to_audio(video_path, audio_path):\n",
        "    \"\"\"\n",
        "    Convert a video file to audio for transcription.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file\n",
        "        audio_path (str): Path to save the extracted audio\n",
        "    \"\"\"\n",
        "    try:\n",
        "        video = VideoFileClip(video_path)\n",
        "        video.audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting video to audio: {str(e)}\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    Transcribe audio file using speech recognition.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert WAV to a format compatible with speech_recognition\n",
        "        sound = AudioSegment.from_file(audio_path)\n",
        "        sound = sound.set_channels(1)  # Convert to mono\n",
        "        sound = sound.set_frame_rate(16000)  # Set frame rate\n",
        "        sound.export(audio_path, format=\"wav\")\n",
        "\n",
        "        recognizer = sr.Recognizer()\n",
        "        with sr.AudioFile(audio_path) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        return f\"Error transcribing audio: {str(e)}\"\n",
        "\n",
        "def extract_video_frames(video_path, output_folder, frames_per_second=1):\n",
        "    \"\"\"\n",
        "    Extract frames from a video file.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file\n",
        "        output_folder (str): Path to save the extracted frames\n",
        "        frames_per_second (float): Number of frames to extract per second\n",
        "\n",
        "    Returns:\n",
        "        list: Paths to extracted frames\n",
        "    \"\"\"\n",
        "    try:\n",
        "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        frames_folder = os.path.join(output_folder, f\"{video_name}_frames\")\n",
        "        os.makedirs(frames_folder, exist_ok=True)\n",
        "\n",
        "        video = VideoFileClip(video_path)\n",
        "        duration = video.duration\n",
        "\n",
        "        # Calculate frame extraction timestamps\n",
        "        timestamps = [i for i in range(0, int(duration), int(1/frames_per_second))]\n",
        "\n",
        "        # Extract frames\n",
        "        frame_paths = []\n",
        "        for i, timestamp in enumerate(timestamps):\n",
        "            frame_path = os.path.join(frames_folder, f\"frame_{i:04d}.jpg\")\n",
        "            video.save_frame(frame_path, timestamp)\n",
        "            frame_paths.append(frame_path)\n",
        "\n",
        "        print(f\"Extracted {len(frame_paths)} frames from {video_path}\")\n",
        "        return frame_paths\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frames from {video_path}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def transcribe_video_with_whisper(video_path, output_path, model_size=\"medium\"):\n",
        "    \"\"\"\n",
        "    Transcribe video using OpenAI's Whisper model.\n",
        "    This requires whisper to be installed: pip install openai-whisper\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file\n",
        "        output_path (str): Path to save the transcription\n",
        "        model_size (str): Whisper model size ('tiny', 'base', 'small', 'medium', 'large')\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the transcript file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create output directory if it doesn't exist\n",
        "        output_dir = os.path.dirname(output_path)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Extract audio from video to a temporary file\n",
        "        audio_filename = f\"temp_{os.path.basename(os.path.splitext(video_path)[0])}.wav\"\n",
        "        audio_path = os.path.join(output_dir, audio_filename)\n",
        "\n",
        "        # Convert video to audio\n",
        "        convert_video_to_audio(video_path, audio_path)\n",
        "\n",
        "        # Use whisper to transcribe\n",
        "        # Specify the exact output file name to force Whisper to use our desired name\n",
        "        base_output_name = os.path.splitext(os.path.basename(output_path))[0]\n",
        "        cmd = f\"whisper {audio_path} --model {model_size} --output_dir {output_dir} --output_format txt\"\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "        # Whisper typically saves the file as {audio_filename}.txt\n",
        "        whisper_output = os.path.join(output_dir, os.path.splitext(audio_filename)[0] + \".txt\")\n",
        "\n",
        "        # If the file exists, rename it to match our desired output path\n",
        "        if os.path.exists(whisper_output) and whisper_output != output_path:\n",
        "            shutil.move(whisper_output, output_path)\n",
        "            print(f\"Moved transcript to: {output_path}\")\n",
        "\n",
        "        # Clean up temporary audio file\n",
        "        if os.path.exists(audio_path):\n",
        "            os.remove(audio_path)\n",
        "\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error using Whisper: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "def extract_pptx_text(pptx_path):\n",
        "    \"\"\"\n",
        "    Extract text from a PowerPoint (PPTX) file.\n",
        "\n",
        "    Args:\n",
        "        pptx_path (str): Path to the PPTX file\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text from the PPTX\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Import here to avoid errors if library isn't installed\n",
        "        from pptx import Presentation\n",
        "\n",
        "        prs = Presentation(pptx_path)\n",
        "        text = \"\"\n",
        "\n",
        "        # Add title slide information if available\n",
        "        if hasattr(prs, 'core_properties') and prs.core_properties.title:\n",
        "            text += f\"Title: {prs.core_properties.title}\\n\\n\"\n",
        "\n",
        "        # Process each slide\n",
        "        for slide_num, slide in enumerate(prs.slides, 1):\n",
        "            text += f\"Slide {slide_num}:\\n\"\n",
        "\n",
        "            # Extract slide title if available\n",
        "            if slide.shapes.title and slide.shapes.title.has_text_frame:\n",
        "                text += f\"Title: {slide.shapes.title.text}\\n\"\n",
        "\n",
        "            # Extract text from all shapes in the slide\n",
        "            for shape in slide.shapes:\n",
        "                if hasattr(shape, \"text\"):\n",
        "                    text += f\"{shape.text}\\n\"\n",
        "                elif hasattr(shape, \"text_frame\"):\n",
        "                    for paragraph in shape.text_frame.paragraphs:\n",
        "                        text += f\"{paragraph.text}\\n\"\n",
        "\n",
        "            # Add notes if available\n",
        "            if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "                notes_text = slide.notes_slide.notes_text_frame.text\n",
        "                if notes_text:\n",
        "                    text += f\"Notes: {notes_text}\\n\"\n",
        "\n",
        "            text += \"\\n\" + \"-\" * 40 + \"\\n\\n\"\n",
        "\n",
        "        return text\n",
        "    except ImportError:\n",
        "        return f\"Error: python-pptx library not installed. Please run: pip install python-pptx\"\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting text from {pptx_path}: {str(e)}\"\n",
        "\n",
        "def extract_pptx_images(pptx_path, output_folder):\n",
        "    \"\"\"\n",
        "    Extract images from a PowerPoint (PPTX) file.\n",
        "\n",
        "    Args:\n",
        "        pptx_path (str): Path to the PPTX file\n",
        "        output_folder (str): Path to save the extracted images\n",
        "\n",
        "    Returns:\n",
        "        list: Paths to extracted images\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from pptx import Presentation\n",
        "        from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
        "        import io\n",
        "        from PIL import Image\n",
        "\n",
        "        pptx_name = os.path.splitext(os.path.basename(pptx_path))[0]\n",
        "        images_folder = os.path.join(output_folder, f\"{pptx_name}_images\")\n",
        "        os.makedirs(images_folder, exist_ok=True)\n",
        "\n",
        "        prs = Presentation(pptx_path)\n",
        "        image_count = 0\n",
        "        image_paths = []\n",
        "\n",
        "        for slide_num, slide in enumerate(prs.slides, 1):\n",
        "            for shape_num, shape in enumerate(slide.shapes, 1):\n",
        "                if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
        "                    image = shape.image\n",
        "                    image_ext = image.ext.lower() if hasattr(image, 'ext') else 'jpg'\n",
        "\n",
        "                    # Make sure ext is valid\n",
        "                    if image_ext not in ['jpg', 'jpeg', 'png', 'gif', 'bmp']:\n",
        "                        image_ext = 'jpg'\n",
        "\n",
        "                    image_path = os.path.join(images_folder, f\"slide_{slide_num}_image_{shape_num}.{image_ext}\")\n",
        "\n",
        "                    # Save the image\n",
        "                    with open(image_path, 'wb') as f:\n",
        "                        f.write(image.blob)\n",
        "\n",
        "                    image_paths.append(image_path)\n",
        "                    image_count += 1\n",
        "\n",
        "        print(f\"Extracted {image_count} images from {pptx_path}\")\n",
        "        return image_paths\n",
        "    except ImportError:\n",
        "        print(f\"Error: python-pptx or PIL library not installed. Please run: pip install python-pptx Pillow\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting images from {pptx_path}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def process_folder(folder_path, output_folder, whisper_model_size=\"medium\", extract_images=True, frames_per_second=0):\n",
        "    \"\"\"\n",
        "    Process all PDF, PowerPoint, and video files in a folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing files\n",
        "        output_folder (str): Path to save the extracted text, images, and transcriptions\n",
        "        whisper_model_size (str): Whisper model size to use for transcription\n",
        "        extract_images (bool): Whether to extract images from PDFs and PPTXs\n",
        "        frames_per_second (float): Number of frames to extract per second from videos. Set to 0 to disable frame extraction.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Dictionary to store extraction results\n",
        "    extraction_results = {}\n",
        "\n",
        "    # Get all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Process each file\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        # Skip directories\n",
        "        if os.path.isdir(file_path):\n",
        "            continue\n",
        "\n",
        "        # Get file extension\n",
        "        _, ext = os.path.splitext(file)\n",
        "        ext = ext.lower()\n",
        "\n",
        "        file_results = {\"file\": file, \"type\": None, \"text_path\": None, \"images\": [], \"frames\": []}\n",
        "        output_path = os.path.join(output_folder, os.path.splitext(file)[0] + \".txt\")\n",
        "\n",
        "        # Process PDF files\n",
        "        if ext == '.pdf':\n",
        "            print(f\"Processing PDF: {file}\")\n",
        "            file_results[\"type\"] = \"pdf\"\n",
        "\n",
        "            # Extract text\n",
        "            text = extract_pdf_text(file_path)\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(text)\n",
        "            file_results[\"text_path\"] = output_path\n",
        "\n",
        "            # Extract images if requested\n",
        "            if extract_images:\n",
        "                image_paths = extract_pdf_images(file_path, output_folder)\n",
        "                file_results[\"images\"] = image_paths\n",
        "                print(f\"Extracted {len(image_paths)} images from {file}\")\n",
        "\n",
        "        # Process PowerPoint files\n",
        "        elif ext in ['.pptx', '.ppt']:\n",
        "            print(f\"Processing PowerPoint: {file}\")\n",
        "            file_results[\"type\"] = \"powerpoint\"\n",
        "\n",
        "            if ext == '.pptx':\n",
        "                text = extract_pptx_text(file_path)\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(text)\n",
        "                file_results[\"text_path\"] = output_path\n",
        "\n",
        "                # Extract images if requested\n",
        "                if extract_images:\n",
        "                    image_paths = extract_pptx_images(file_path, output_folder)\n",
        "                    file_results[\"images\"] = image_paths\n",
        "                    print(f\"Extracted {len(image_paths)} images from {file}\")\n",
        "            else:\n",
        "                print(f\"Warning: .ppt format not supported directly. Please convert to .pptx\")\n",
        "\n",
        "        # Process video files\n",
        "        elif ext in ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv']:\n",
        "            print(f\"Processing video: {file}\")\n",
        "            file_results[\"type\"] = \"video\"\n",
        "\n",
        "            # Extract frames if requested and frames_per_second > 0\n",
        "            if extract_images and frames_per_second > 0:\n",
        "                frame_paths = extract_video_frames(file_path, output_folder, frames_per_second)\n",
        "                file_results[\"frames\"] = frame_paths\n",
        "                print(f\"Extracted {len(frame_paths)} frames from {file}\")\n",
        "            else:\n",
        "                print(f\"Skipping frame extraction for {file}\")\n",
        "\n",
        "            # Using Whisper for better transcription results\n",
        "            print(f\"Transcribing with Whisper: {file}\")\n",
        "            transcript_path = transcribe_video_with_whisper(file_path, output_path, whisper_model_size)\n",
        "\n",
        "            # If Whisper fails for some reason, fall back to basic transcription\n",
        "            if isinstance(transcript_path, str) and transcript_path.startswith(\"Error\"):\n",
        "                print(f\"Whisper failed, falling back to basic transcription: {file}\")\n",
        "                temp_audio_path = os.path.join(output_folder, f\"temp_{os.path.splitext(file)[0]}.wav\")\n",
        "                convert_video_to_audio(file_path, temp_audio_path)\n",
        "                transcript = transcribe_audio(temp_audio_path)\n",
        "\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(transcript)\n",
        "\n",
        "                # Clean up temporary files\n",
        "                if os.path.exists(temp_audio_path):\n",
        "                    os.remove(temp_audio_path)\n",
        "\n",
        "                file_results[\"text_path\"] = output_path\n",
        "            else:\n",
        "                print(f\"Whisper transcription saved to: {transcript_path}\")\n",
        "                file_results[\"text_path\"] = transcript_path\n",
        "\n",
        "                # Verify file exists\n",
        "                if not os.path.exists(transcript_path):\n",
        "                    print(f\"WARNING: Expected transcript file not found at {transcript_path}\")\n",
        "                else:\n",
        "                    print(f\"Confirmed transcript file exists at {transcript_path}\")\n",
        "                    # Print first few lines of transcript for verification\n",
        "                    try:\n",
        "                        with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "                            first_lines = \"\".join([next(f) for _ in range(3)])\n",
        "                            print(f\"First few lines of transcript: {first_lines}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Could not read transcript file: {e}\")\n",
        "\n",
        "        # Add to results dictionary\n",
        "        extraction_results[file] = file_results\n",
        "\n",
        "    # Save extraction results as JSON\n",
        "    results_path = os.path.join(output_folder, \"extraction_results.json\")\n",
        "    with open(results_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(extraction_results, f, indent=2)\n",
        "\n",
        "    print(f\"Processing complete. Results saved to {output_folder}\")\n",
        "    print(f\"Extraction summary saved to {results_path}\")\n",
        "\n",
        "    return extraction_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # For Google Colab usage - no command line arguments needed\n",
        "    # Just set your input and output folder paths directly:\n",
        "    input_folder = \"/content/LLM_DATASET/LLM_DATASET/BST\"  # Change this to your input folder path\n",
        "    output_folder = \"/content/output_folder\"  # Change this to your output folder path\n",
        "    whisper_model = \"medium\"  # Options: 'tiny', 'base', 'small', 'medium', 'large'\n",
        "    extract_images = True  # Set to False if you only want text\n",
        "    frames_per_second = 0  # Set to 0 to disable video frame extraction\n",
        "\n",
        "    # Install required dependencies first\n",
        "    print(\"Installing required dependencies...\")\n",
        "    subprocess.run([\"pip\", \"install\", \"PyPDF2\", \"SpeechRecognition\", \"pydub\", \"moviepy\",\n",
        "                   \"python-pptx\", \"Pillow\", \"PyMuPDF\"], check=True)\n",
        "\n",
        "    # Check if poppler-utils is installed (for pdfimages), install if not\n",
        "    try:\n",
        "        subprocess.run([\"pdfimages\", \"-v\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(\"poppler-utils is already installed.\")\n",
        "    except:\n",
        "        print(\"Installing poppler-utils for better PDF image extraction...\")\n",
        "        subprocess.run([\"apt-get\", \"update\"], check=True)\n",
        "        subprocess.run([\"apt-get\", \"install\", \"-y\", \"poppler-utils\"], check=True)\n",
        "        print(\"poppler-utils installed successfully.\")\n",
        "\n",
        "    # Check if whisper is installed, install if not\n",
        "    try:\n",
        "        subprocess.run([\"whisper\", \"--help\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(\"Whisper is already installed.\")\n",
        "    except:\n",
        "        print(\"Installing Whisper...\")\n",
        "        subprocess.run([\"pip\", \"install\", \"openai-whisper\"], check=True)\n",
        "        print(\"Whisper installed successfully.\")\n",
        "\n",
        "    # Check if FFmpeg is installed, install if not\n",
        "    try:\n",
        "        subprocess.run([\"ffmpeg\", \"-version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(\"FFmpeg is already installed.\")\n",
        "    except:\n",
        "        print(\"Installing FFmpeg...\")\n",
        "        subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], check=True)\n",
        "        print(\"FFmpeg installed successfully.\")\n",
        "\n",
        "    print(f\"Processing files from {input_folder}\")\n",
        "    process_folder(input_folder, output_folder, whisper_model, extract_images, frames_per_second)\n",
        "    print(f\"Done! Extracted texts, images, and transcriptions saved to {output_folder}\")\n",
        "    print(f\"Note: Video frame extraction is disabled (frames_per_second=0)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1faddbef85364fa19d0178c8bb7d95b8",
            "2435b7c7ed164a4898f5bc64bef2585b",
            "ab8aea5172f947b1b0eb8e09f31020d0",
            "8b6516de9b7d46bfb723bbba90e3de0c",
            "02c957e2beee4e968ca54ca7c0bff0df",
            "8a3f6f3e91f348fca9e22f67bdd97613",
            "4f72dd9d723b4773bc832eefc49ea26f",
            "31091df2baa74885a4f1870366232d6c",
            "8015f10bad5f4947a4b4b41c85b84062",
            "a157069cca0e42fb87fdca4f1cdddbda",
            "965c42e01943456dae8e71271b21a3d9",
            "e190c6eed0a44deebe760cfa25d117e9",
            "a34a9e1c71e640ed9d5baea711387937",
            "a5b6782416ca47a7be54d10230b10c08",
            "432e7e26e2d145cda0a952b58408c929",
            "eabf729c3c244e0896800f99b878a1fd",
            "a057909f7c754f0bbbc2d2c3d0322956",
            "2c5e727c5be847e9890f2acf2cf80719",
            "479d18aabb8b49ee8fa3755419da21ca",
            "1af3087604ac468396c6a27b339620a0",
            "95757e0c687c44ebaf301c4ad7bc7442",
            "2cc4008e09ff46229eb90451acadc1d4",
            "b55331ba2c354aa8891ad6cbeb01592f",
            "f3118c66e3564a699ac2d3dbed2ecee9",
            "c32612a157d84147af4992619de256b6",
            "f04a8192e5114c47948a09cb4837530b",
            "2e7f41bc08f34447b921573ee64bf27b",
            "34aa0e48509d422f8b29c88a73d787c1",
            "239a40fc59504cd89a545e4d30812fd1",
            "66ae8717028c4e44a5dcb9dfb454c3cb",
            "690aceaa89ed4160a07a105acf2b6447",
            "143e7e3f017f494db7af5f182e4f9e95",
            "85b2dcbecce94d4eb07c2115b713b2b5",
            "27a0557c959747b3b24e6df29d73b8e0",
            "32fd232365024aab952dc138b13ffedf",
            "38f401db6ac54462ae18b95df79d04ec",
            "22f60a25e3f14ae9901a7e3da89b5f37",
            "029b0ab53fb94ea78bf6f93f5b514afe",
            "1aef539df0d441b4a2f0ed1aa49a819a",
            "0bf47be59af644e6b0e289d007793d4d",
            "ff786f9f66ea43adbac990c21642f0c8",
            "c941b50f564d4f3f9281fe4269fbb176",
            "e3142df156bb49efa81cdce010d651e4",
            "85a1c8f6c05f4a48939a6fc70aac447b",
            "2ce2a8d0d14143e6a815d663693ed43e",
            "4e4f5a270fd342fab0b5854893b003b9",
            "2e50cec71a924a039624f63c5cbb7a71",
            "2399ac4ec09f4dfe8435a5b5085dcb9e",
            "f30ca15a1d0b432881a3850690553ec7",
            "9ee6f1579912480cb620ef20ecd6c49b",
            "20a9ffb22a5e4bb48633a2e71b99f3fc",
            "a421692915784383a4e87d909134266c",
            "3ba3af88bfc94900a28c14df06b747f4",
            "bce71b33f77341a4a7938e8741a8bc66",
            "a138eb8afdfc44c780b9b9278e54a8b4"
          ]
        },
        "id": "i-xsF6MppvSj",
        "outputId": "1af4b4e5-530a-4893-f04e-de181e633ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (0.21.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.5\n",
            "✅ GPU is available: Tesla T4\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu==1.7.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1faddbef85364fa19d0178c8bb7d95b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e190c6eed0a44deebe760cfa25d117e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b55331ba2c354aa8891ad6cbeb01592f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27a0557c959747b3b24e6df29d73b8e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ce2a8d0d14143e6a815d663693ed43e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Successfully authenticated and can access Gemma model!\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -U \"transformers[torch]\" \"tokenizers>=0.21,<0.22\"\n",
        "!pip install langchain langchain_community\n",
        "!pip install faiss-cpu\n",
        "!pip install accelerate bitsandbytes sentence-transformers tqdm huggingface_hub\n",
        "\n",
        "# Check for GPU and install faiss-gpu if available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✅ GPU is available: {torch.cuda.get_device_name(0)}\")\n",
        "    !pip install faiss-gpu==1.7.2\n",
        "else:\n",
        "    print(\"⚠️ WARNING: GPU not available. Processing will be much slower.\")\n",
        "\n",
        "# Set environment variable to avoid tokenizer parallelism warning\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Hugging Face authentication\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Either securely prompt for the token, or hardcode it (not recommended)\n",
        "# Uncomment below if you want to enter securely\n",
        "# import getpass\n",
        "# HF_TOKEN = getpass.getpass(\"Enter your Hugging Face token: \")\n",
        "HF_TOKEN = \"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\"  # Replace with your actual token\n",
        "\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# Test model access with AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-27b-it\", token=HF_TOKEN)\n",
        "    print(\"✅ Successfully authenticated and can access Gemma model!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error accessing Gemma model: {e}\")\n",
        "    print(\"Please check your Hugging Face token and make sure you've accepted the model terms.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "4360f6d1afbd408c8f0ed47767708f3f",
            "60df02bc3dca42a098d251b5ec076959",
            "91e2a189eb864017bdef9a6c4745ef92",
            "f5929f6ac17f418c985a9436876807e0",
            "7c299c804aa244cca18c96c57a7f439a",
            "67247f8ccac04e83a73455f284ce8e42",
            "390073a45e494a3994f30146adfa6d57",
            "6a0f761ea73b40f3a104375380d51577",
            "9fdf3ccba6d44a7a8a7d9a835fdbd90c",
            "b7f0d74241ae49ce98b627e5181419c3",
            "aea4eadbe6ed45938ffe0d04ba7d41f4"
          ]
        },
        "id": "ixg9huyasRkH",
        "outputId": "fd5f396e-020c-47d1-f718-97c893066607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading existing vector database...\n",
            "Setting up model: mistralai/Mistral-7B-Instruct-v0.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4360f6d1afbd408c8f0ed47767708f3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing query: What are the main concepts covered in these documents?\n",
            "Retrieving documents for query: 'What are the main concepts covered in these documents?'\n",
            "Generating summary with Mistral...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 1/5 [00:31<02:05, 31.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing query: Summarize the key points about bst\n",
            "Retrieving documents for query: 'Summarize the key points about bst'\n",
            "Generating summary with Mistral...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [01:14<01:55, 38.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing query: What algorithms are discussed in the lectures?\n",
            "Retrieving documents for query: 'What algorithms are discussed in the lectures?'\n",
            "Generating summary with Mistral...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [02:04<01:26, 43.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing query: Explain the main technical concepts in simple terms\n",
            "Retrieving documents for query: 'Explain the main technical concepts in simple terms'\n",
            "Generating summary with Mistral...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [02:43<00:41, 41.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing query: What is threaded bst\n",
            "Retrieving documents for query: 'What is threaded bst'\n",
            "Generating summary with Mistral...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [03:21<00:00, 40.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved summaries to /content/output_folder/rag_summaries.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Safely import FAISS\n",
        "try:\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "except ImportError:\n",
        "    print(\"Error importing FAISS from langchain. Trying direct import...\")\n",
        "    try:\n",
        "        import faiss\n",
        "        print(\"Successfully imported faiss directly.\")\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "    except ImportError:\n",
        "        print(\"Could not import faiss. Installing faiss-cpu...\")\n",
        "        os.system(\"pip install faiss-cpu\")\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Set up paths\n",
        "INPUT_DIR = \"/content/output_folder\"  # Directory containing extracted text files\n",
        "VECTOR_DB_PATH = \"/content/vector_db\"  # Path to save the vector database\n",
        "HF_TOKEN = \"**\"  # Your Hugging Face token\n",
        "\n",
        "# Model configuration - using Mistral 7B Instruct v0.3\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Mistral 7B Instruction model\n",
        "CHUNK_SIZE = 1200  # Chunk size for document splitting\n",
        "CHUNK_OVERLAP = 300  # Overlap between chunks\n",
        "MAX_NEW_TOKENS = 768  # Maximum new tokens to generate\n",
        "TEMPERATURE = 0.6  # Temperature for generation\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
        "\n",
        "def load_extracted_texts(input_dir):\n",
        "    \"\"\"\n",
        "    Load all extracted text files from the output directory.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory containing extracted text files\n",
        "\n",
        "    Returns:\n",
        "        list: List of Document objects with text content and metadata\n",
        "    \"\"\"\n",
        "    print(\"Loading extracted text files...\")\n",
        "    documents = []\n",
        "\n",
        "    # Try to load extraction summary if available\n",
        "    summary_path = os.path.join(input_dir, \"extraction_results.json\")\n",
        "    file_metadata = {}\n",
        "\n",
        "    if os.path.exists(summary_path):\n",
        "        try:\n",
        "            with open(summary_path, 'r', encoding='utf-8') as f:\n",
        "                extraction_results = json.load(f)\n",
        "\n",
        "            # Extract metadata from the summary\n",
        "            for filename, info in extraction_results.items():\n",
        "                if info.get(\"text_path\"):\n",
        "                    file_metadata[os.path.basename(info[\"text_path\"])] = {\n",
        "                        \"source_file\": filename,\n",
        "                        \"file_type\": info.get(\"type\", \"unknown\"),\n",
        "                        \"has_images\": len(info.get(\"images\", [])) > 0 or len(info.get(\"frames\", [])) > 0\n",
        "                    }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading extraction summary: {e}\")\n",
        "\n",
        "    # Get all text files\n",
        "    text_files = glob.glob(os.path.join(input_dir, \"*.txt\"))\n",
        "\n",
        "    # Load each text file\n",
        "    for text_file in tqdm(text_files):\n",
        "        filename = os.path.basename(text_file)\n",
        "        try:\n",
        "            with open(text_file, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            # Skip empty files or very short files\n",
        "            if len(text.strip()) < 50:\n",
        "                print(f\"Skipping short/empty file: {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Get metadata if available\n",
        "            meta = file_metadata.get(filename, {})\n",
        "            meta.update({\n",
        "                \"source\": filename,\n",
        "                \"path\": text_file\n",
        "            })\n",
        "\n",
        "            documents.append(Document(page_content=text, metadata=meta))\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {text_file}: {e}\")\n",
        "\n",
        "    print(f\"Loaded {len(documents)} documents\")\n",
        "    return documents\n",
        "\n",
        "def create_vector_database(documents):\n",
        "    \"\"\"\n",
        "    Create a vector database from the documents.\n",
        "\n",
        "    Args:\n",
        "        documents (list): List of Document objects\n",
        "\n",
        "    Returns:\n",
        "        FAISS: FAISS vector store\n",
        "    \"\"\"\n",
        "    print(\"Splitting documents into chunks...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        chunk_overlap=CHUNK_OVERLAP,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        print(f\"Split into {len(chunks)} chunks\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text splitting: {e}\")\n",
        "        # Fallback to simpler splitting if recursive splitter fails\n",
        "        from langchain.text_splitter import CharacterTextSplitter\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            separator=\"\\n\"\n",
        "        )\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        print(f\"Used fallback splitter. Split into {len(chunks)} chunks\")\n",
        "\n",
        "    print(\"Creating embeddings (this may take a while)...\")\n",
        "    # Use a sentence-transformer model for embeddings\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
        "    )\n",
        "\n",
        "    print(\"Building vector database...\")\n",
        "    try:\n",
        "        vector_db = FAISS.from_documents(chunks, embedding_model)\n",
        "        print(f\"Saving vector database to {VECTOR_DB_PATH}\")\n",
        "        vector_db.save_local(VECTOR_DB_PATH)\n",
        "        return vector_db\n",
        "    except Exception as e:\n",
        "        print(f\"Error building vector database: {e}\")\n",
        "        raise\n",
        "\n",
        "def load_vector_database():\n",
        "    \"\"\"\n",
        "    Load the vector database if it exists, otherwise create it.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: FAISS vector store\n",
        "    \"\"\"\n",
        "    if os.path.exists(os.path.join(VECTOR_DB_PATH, \"index.faiss\")):\n",
        "        print(\"Loading existing vector database...\")\n",
        "        try:\n",
        "            embedding_model = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
        "            )\n",
        "            vector_db = FAISS.load_local(VECTOR_DB_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
        "            return vector_db\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading vector database: {e}\")\n",
        "            print(\"Creating a new vector database instead...\")\n",
        "            # Remove corrupted database files\n",
        "            for file in [\"index.faiss\", \"index.pkl\"]:\n",
        "                file_path = os.path.join(VECTOR_DB_PATH, file)\n",
        "                if os.path.exists(file_path):\n",
        "                    os.remove(file_path)\n",
        "\n",
        "    print(\"Creating a new vector database...\")\n",
        "    documents = load_extracted_texts(INPUT_DIR)\n",
        "    return create_vector_database(documents)\n",
        "\n",
        "def setup_mistral_model():\n",
        "    \"\"\"\n",
        "    Set up the Mistral model for text generation.\n",
        "\n",
        "    Returns:\n",
        "        pipeline: Hugging Face text generation pipeline\n",
        "    \"\"\"\n",
        "    print(f\"Setting up model: {MODEL_ID}\")\n",
        "\n",
        "    try:\n",
        "        # Load the tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "        # Configure 4-bit quantization for memory efficiency\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "        )\n",
        "\n",
        "        # Load the model with quantization\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_ID,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=quantization_config,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Create the pipeline\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            do_sample=True,\n",
        "            temperature=TEMPERATURE,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "        return pipe\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up Mistral model: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_summary(query, vector_db, generator, num_docs=5):\n",
        "    \"\"\"\n",
        "    Generate a summary of the relevant documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): Query to search for\n",
        "        vector_db (FAISS): Vector database\n",
        "        generator (pipeline): Text generation pipeline\n",
        "        num_docs (int): Number of documents to retrieve\n",
        "\n",
        "    Returns:\n",
        "        str: Generated summary\n",
        "    \"\"\"\n",
        "    print(f\"Retrieving documents for query: '{query}'\")\n",
        "\n",
        "    try:\n",
        "        # Retrieve relevant documents\n",
        "        retrieved_docs = vector_db.similarity_search(query, k=num_docs)\n",
        "\n",
        "        # Handle case where no documents are retrieved\n",
        "        if not retrieved_docs:\n",
        "            return \"No relevant documents found for your query.\"\n",
        "\n",
        "        # Construct context from retrieved documents\n",
        "        context = \"\"\n",
        "        for i, doc in enumerate(retrieved_docs):\n",
        "            source = doc.metadata.get(\"source\", f\"Document {i+1}\")\n",
        "            # Limit very long chunks to prevent context overflow\n",
        "            truncated_content = doc.page_content[:1500] + \"...\" if len(doc.page_content) > 1500 else doc.page_content\n",
        "            context += f\"\\n--- Document {i+1}: {source} ---\\n{truncated_content}\\n\"\n",
        "\n",
        "        # Mistral-specific prompt format with proper instruction format\n",
        "        prompt = f\"\"\"<s>[INST] I need you to summarize information from several documents based on a specific query.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Here are relevant passages from the documents:\n",
        "{context}\n",
        "\n",
        "Please provide a comprehensive and accurate summary that addresses the query based solely on the information in these documents. Include the most important points and insights, but keep your response concise and well-organized. [/INST]\"\"\"\n",
        "\n",
        "        print(\"Generating summary with Mistral...\")\n",
        "        # Generate the summary\n",
        "        result = generator(prompt)\n",
        "\n",
        "        # Extract the generated text\n",
        "        summary = result[0][\"generated_text\"]\n",
        "\n",
        "        # Remove the prompt from the response\n",
        "        summary = summary[len(prompt):]\n",
        "\n",
        "        # Clean up any Mistral-specific tokens\n",
        "        if \"</s>\" in summary:\n",
        "            summary = summary.split(\"</s>\")[0].strip()\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summary generation: {e}\")\n",
        "        return f\"An error occurred while generating the summary: {str(e)}\"\n",
        "\n",
        "def save_conversation(queries, summaries):\n",
        "    \"\"\"\n",
        "    Save the conversation history to a file.\n",
        "\n",
        "    Args:\n",
        "        queries (list): List of queries\n",
        "        summaries (list): List of summaries\n",
        "    \"\"\"\n",
        "    conversation = []\n",
        "    for q, s in zip(queries, summaries):\n",
        "        conversation.append({\"query\": q, \"summary\": s})\n",
        "\n",
        "    output_path = os.path.join(INPUT_DIR, \"conversation_history.json\")\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(conversation, f, indent=2)\n",
        "\n",
        "    print(f\"Saved conversation history to {output_path}\")\n",
        "\n",
        "def interactive_rag():\n",
        "    \"\"\"\n",
        "    Run the RAG system in an interactive mode.\n",
        "    \"\"\"\n",
        "    print(\"Loading vector database...\")\n",
        "    try:\n",
        "        vector_db = load_vector_database()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load vector database: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"Setting up Mistral model...\")\n",
        "    try:\n",
        "        generator = setup_mistral_model()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to set up Mistral model: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n=== RAG System with Mistral-7B-Instruct-v0.3 Ready ===\")\n",
        "    print(\"Enter your query (or 'exit' to quit, 'save' to save conversation):\")\n",
        "\n",
        "    queries = []\n",
        "    summaries = []\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nQuery: \")\n",
        "        if query.lower() in ['exit', 'quit']:\n",
        "            break\n",
        "        elif query.lower() == 'save':\n",
        "            save_conversation(queries, summaries)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            summary = generate_summary(query, vector_db, generator)\n",
        "            print(\"\\n=== Summary ===\")\n",
        "            print(summary)\n",
        "\n",
        "            # Save to conversation history\n",
        "            queries.append(query)\n",
        "            summaries.append(summary)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating summary: {e}\")\n",
        "\n",
        "    # Save conversation at the end\n",
        "    if queries:\n",
        "        save_conversation(queries, summaries)\n",
        "\n",
        "def batch_summarize(queries):\n",
        "    \"\"\"\n",
        "    Summarize a list of predefined queries in batch mode.\n",
        "\n",
        "    Args:\n",
        "        queries (list): List of query strings\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping queries to summaries\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vector_db = load_vector_database()\n",
        "        generator = setup_mistral_model()\n",
        "\n",
        "        results = {}\n",
        "        for query in tqdm(queries):\n",
        "            print(f\"Processing query: {query}\")\n",
        "            try:\n",
        "                summary = generate_summary(query, vector_db, generator)\n",
        "                results[query] = summary\n",
        "            except Exception as e:\n",
        "                results[query] = f\"Error: {str(e)}\"\n",
        "\n",
        "        # Save results to file\n",
        "        output_path = os.path.join(INPUT_DIR, \"rag_summaries.json\")\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        print(f\"Saved summaries to {output_path}\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error in batch summarization: {e}\")\n",
        "        return {}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Choose whether to run in interactive or batch mode\n",
        "    mode = \"interacti\"  # or \"batch\"\n",
        "\n",
        "    if mode == \"interactive\":\n",
        "        interactive_rag()\n",
        "    else:\n",
        "        # Example predefined queries for batch mode\n",
        "        queries = [\n",
        "            \"What are the main concepts covered in these documents?\",\n",
        "            \"Summarize the key points about bst\",\n",
        "            \"What algorithms are discussed in the lectures?\",\n",
        "            \"Explain the main technical concepts in simple terms\",\n",
        "            \"What is threaded bst\"\n",
        "        ]\n",
        "        batch_summarize(queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7cg33Mitj09",
        "outputId": "b5881199-716f-4750-e6d4-d30ad62f4faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updating vector database at /content/vector_db with files from /content/output_folder\n",
            "Loading existing vector database from /content/vector_db...\n",
            "Successfully loaded existing vector database with 8 entries\n",
            "Loading new text files from /content/output_folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 10284.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 6 new documents\n",
            "Splitting documents into chunks...\n",
            "Split into 32 chunks\n",
            "Adding 32 new chunks to the vector database...\n",
            "Successfully added new documents to vector database\n",
            "Saving updated vector database to /content/vector_db\n",
            "Vector database successfully updated and saved\n",
            "Vector database update complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Safely import FAISS\n",
        "try:\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "except ImportError:\n",
        "    print(\"Error importing FAISS from langchain. Trying direct import...\")\n",
        "    try:\n",
        "        import faiss\n",
        "        print(\"Successfully imported faiss directly.\")\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "    except ImportError:\n",
        "        print(\"Could not import faiss. Installing faiss-cpu...\")\n",
        "        os.system(\"pip install faiss-cpu\")\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Set up paths\n",
        "EXISTING_VECTOR_DB_PATH = \"/content/vector_db\"  # Path to existing vector database\n",
        "NEW_FILES_DIR = \"/content/new_files\"  # Directory containing new text files to add\n",
        "HF_TOKEN = \"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\"  # Your Hugging Face token\n",
        "\n",
        "# Model configuration\n",
        "CHUNK_SIZE = 1200  # Chunk size for document splitting\n",
        "CHUNK_OVERLAP = 300  # Overlap between chunks\n",
        "\n",
        "def load_new_text_files(input_dir):\n",
        "    \"\"\"\n",
        "    Load all new text files to be added to the vector database.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory containing new text files\n",
        "\n",
        "    Returns:\n",
        "        list: List of Document objects with text content and metadata\n",
        "    \"\"\"\n",
        "    print(f\"Loading new text files from {input_dir}...\")\n",
        "    documents = []\n",
        "\n",
        "    # Try to load extraction summary if available\n",
        "    summary_path = os.path.join(input_dir, \"extraction_results.json\")\n",
        "    file_metadata = {}\n",
        "\n",
        "    if os.path.exists(summary_path):\n",
        "        try:\n",
        "            with open(summary_path, 'r', encoding='utf-8') as f:\n",
        "                extraction_results = json.load(f)\n",
        "\n",
        "            # Extract metadata from the summary\n",
        "            for filename, info in extraction_results.items():\n",
        "                if info.get(\"text_path\"):\n",
        "                    file_metadata[os.path.basename(info[\"text_path\"])] = {\n",
        "                        \"source_file\": filename,\n",
        "                        \"file_type\": info.get(\"type\", \"unknown\"),\n",
        "                        \"has_images\": len(info.get(\"images\", [])) > 0 or len(info.get(\"frames\", [])) > 0\n",
        "                    }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading extraction summary: {e}\")\n",
        "\n",
        "    # Get all text files\n",
        "    text_files = glob.glob(os.path.join(input_dir, \"*.txt\"))\n",
        "\n",
        "    # Load each text file\n",
        "    for text_file in tqdm(text_files):\n",
        "        filename = os.path.basename(text_file)\n",
        "        try:\n",
        "            with open(text_file, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            # Skip empty files or very short files\n",
        "            if len(text.strip()) < 50:\n",
        "                print(f\"Skipping short/empty file: {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Get metadata if available\n",
        "            meta = file_metadata.get(filename, {})\n",
        "            meta.update({\n",
        "                \"source\": filename,\n",
        "                \"path\": text_file,\n",
        "                \"is_new\": True  # Mark as new document\n",
        "            })\n",
        "\n",
        "            documents.append(Document(page_content=text, metadata=meta))\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {text_file}: {e}\")\n",
        "\n",
        "    print(f\"Loaded {len(documents)} new documents\")\n",
        "    return documents\n",
        "\n",
        "def process_documents_into_chunks(documents):\n",
        "    \"\"\"\n",
        "    Process documents into chunks ready for embedding.\n",
        "\n",
        "    Args:\n",
        "        documents (list): List of Document objects\n",
        "\n",
        "    Returns:\n",
        "        list: List of chunks\n",
        "    \"\"\"\n",
        "    print(\"Splitting documents into chunks...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        chunk_overlap=CHUNK_OVERLAP,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        print(f\"Split into {len(chunks)} chunks\")\n",
        "        return chunks\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text splitting: {e}\")\n",
        "        # Fallback to simpler splitting if recursive splitter fails\n",
        "        from langchain.text_splitter import CharacterTextSplitter\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            separator=\"\\n\"\n",
        "        )\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        print(f\"Used fallback splitter. Split into {len(chunks)} chunks\")\n",
        "        return chunks\n",
        "\n",
        "def update_vector_database(new_files_dir, vector_db_path):\n",
        "    \"\"\"\n",
        "    Update an existing vector database with new files.\n",
        "\n",
        "    Args:\n",
        "        new_files_dir (str): Directory containing new text files\n",
        "        vector_db_path (str): Path to the existing vector database\n",
        "\n",
        "    Returns:\n",
        "        FAISS: Updated FAISS vector store\n",
        "    \"\"\"\n",
        "    # Set up the embedding model\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
        "    )\n",
        "\n",
        "    # Check if the vector database exists\n",
        "    if not os.path.exists(os.path.join(vector_db_path, \"index.faiss\")):\n",
        "        print(f\"Error: Vector database not found at {vector_db_path}\")\n",
        "        print(\"Please make sure the vector database exists before updating.\")\n",
        "        return None\n",
        "\n",
        "    # Load the existing vector database\n",
        "    print(f\"Loading existing vector database from {vector_db_path}...\")\n",
        "    try:\n",
        "        vector_db = FAISS.load_local(vector_db_path, embedding_model, allow_dangerous_deserialization=True)\n",
        "        print(f\"Successfully loaded existing vector database with {len(vector_db.index_to_docstore_id)} entries\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Load and process new documents\n",
        "    new_documents = load_new_text_files(new_files_dir)\n",
        "\n",
        "    if not new_documents:\n",
        "        print(\"No new documents to add. Vector database remains unchanged.\")\n",
        "        return vector_db\n",
        "\n",
        "    # Process the new documents into chunks\n",
        "    new_chunks = process_documents_into_chunks(new_documents)\n",
        "\n",
        "    if not new_chunks:\n",
        "        print(\"No chunks created from new documents. Vector database remains unchanged.\")\n",
        "        return vector_db\n",
        "\n",
        "    # Add the new chunks to the vector database\n",
        "    print(f\"Adding {len(new_chunks)} new chunks to the vector database...\")\n",
        "    try:\n",
        "        vector_db.add_documents(new_chunks)\n",
        "        print(\"Successfully added new documents to vector database\")\n",
        "\n",
        "        # Save the updated vector database\n",
        "        print(f\"Saving updated vector database to {vector_db_path}\")\n",
        "        vector_db.save_local(vector_db_path)\n",
        "        print(\"Vector database successfully updated and saved\")\n",
        "\n",
        "        return vector_db\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    # Configuration - modify these paths as needed\n",
        "    existing_vector_db_path = \"/content/vector_db\"\n",
        "    new_files_dir = \"/content/output_folder\"\n",
        "\n",
        "    # Create the new files directory if it doesn't exist\n",
        "    os.makedirs(new_files_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Updating vector database at {existing_vector_db_path} with files from {new_files_dir}\")\n",
        "\n",
        "    # Update the vector database\n",
        "    updated_db = update_vector_database(new_files_dir, existing_vector_db_path)\n",
        "\n",
        "    if updated_db:\n",
        "        print(\"Vector database update complete!\")\n",
        "        # You can use the updated_db for queries right away if needed\n",
        "    else:\n",
        "        print(\"Vector database update failed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEPNn-tsM5GP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "029b0ab53fb94ea78bf6f93f5b514afe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c957e2beee4e968ca54ca7c0bff0df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf47be59af644e6b0e289d007793d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143e7e3f017f494db7af5f182e4f9e95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aef539df0d441b4a2f0ed1aa49a819a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af3087604ac468396c6a27b339620a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1faddbef85364fa19d0178c8bb7d95b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2435b7c7ed164a4898f5bc64bef2585b",
              "IPY_MODEL_ab8aea5172f947b1b0eb8e09f31020d0",
              "IPY_MODEL_8b6516de9b7d46bfb723bbba90e3de0c"
            ],
            "layout": "IPY_MODEL_02c957e2beee4e968ca54ca7c0bff0df"
          }
        },
        "20a9ffb22a5e4bb48633a2e71b99f3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22f60a25e3f14ae9901a7e3da89b5f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3142df156bb49efa81cdce010d651e4",
            "placeholder": "​",
            "style": "IPY_MODEL_85a1c8f6c05f4a48939a6fc70aac447b",
            "value": " 35.0/35.0 [00:00&lt;00:00, 3.96kB/s]"
          }
        },
        "2399ac4ec09f4dfe8435a5b5085dcb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce71b33f77341a4a7938e8741a8bc66",
            "placeholder": "​",
            "style": "IPY_MODEL_a138eb8afdfc44c780b9b9278e54a8b4",
            "value": " 662/662 [00:00&lt;00:00, 50.1kB/s]"
          }
        },
        "239a40fc59504cd89a545e4d30812fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2435b7c7ed164a4898f5bc64bef2585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3f6f3e91f348fca9e22f67bdd97613",
            "placeholder": "​",
            "style": "IPY_MODEL_4f72dd9d723b4773bc832eefc49ea26f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "27a0557c959747b3b24e6df29d73b8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32fd232365024aab952dc138b13ffedf",
              "IPY_MODEL_38f401db6ac54462ae18b95df79d04ec",
              "IPY_MODEL_22f60a25e3f14ae9901a7e3da89b5f37"
            ],
            "layout": "IPY_MODEL_029b0ab53fb94ea78bf6f93f5b514afe"
          }
        },
        "2c5e727c5be847e9890f2acf2cf80719": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cc4008e09ff46229eb90451acadc1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce2a8d0d14143e6a815d663693ed43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e4f5a270fd342fab0b5854893b003b9",
              "IPY_MODEL_2e50cec71a924a039624f63c5cbb7a71",
              "IPY_MODEL_2399ac4ec09f4dfe8435a5b5085dcb9e"
            ],
            "layout": "IPY_MODEL_f30ca15a1d0b432881a3850690553ec7"
          }
        },
        "2e50cec71a924a039624f63c5cbb7a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a421692915784383a4e87d909134266c",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba3af88bfc94900a28c14df06b747f4",
            "value": 662
          }
        },
        "2e7f41bc08f34447b921573ee64bf27b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31091df2baa74885a4f1870366232d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fd232365024aab952dc138b13ffedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aef539df0d441b4a2f0ed1aa49a819a",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf47be59af644e6b0e289d007793d4d",
            "value": "added_tokens.json: 100%"
          }
        },
        "34aa0e48509d422f8b29c88a73d787c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f401db6ac54462ae18b95df79d04ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff786f9f66ea43adbac990c21642f0c8",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c941b50f564d4f3f9281fe4269fbb176",
            "value": 35
          }
        },
        "390073a45e494a3994f30146adfa6d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ba3af88bfc94900a28c14df06b747f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "432e7e26e2d145cda0a952b58408c929": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95757e0c687c44ebaf301c4ad7bc7442",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc4008e09ff46229eb90451acadc1d4",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 37.7MB/s]"
          }
        },
        "4360f6d1afbd408c8f0ed47767708f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60df02bc3dca42a098d251b5ec076959",
              "IPY_MODEL_91e2a189eb864017bdef9a6c4745ef92",
              "IPY_MODEL_f5929f6ac17f418c985a9436876807e0"
            ],
            "layout": "IPY_MODEL_7c299c804aa244cca18c96c57a7f439a"
          }
        },
        "479d18aabb8b49ee8fa3755419da21ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4f5a270fd342fab0b5854893b003b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee6f1579912480cb620ef20ecd6c49b",
            "placeholder": "​",
            "style": "IPY_MODEL_20a9ffb22a5e4bb48633a2e71b99f3fc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f72dd9d723b4773bc832eefc49ea26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60df02bc3dca42a098d251b5ec076959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67247f8ccac04e83a73455f284ce8e42",
            "placeholder": "​",
            "style": "IPY_MODEL_390073a45e494a3994f30146adfa6d57",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "66ae8717028c4e44a5dcb9dfb454c3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67247f8ccac04e83a73455f284ce8e42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690aceaa89ed4160a07a105acf2b6447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a0f761ea73b40f3a104375380d51577": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c299c804aa244cca18c96c57a7f439a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8015f10bad5f4947a4b4b41c85b84062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85a1c8f6c05f4a48939a6fc70aac447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85b2dcbecce94d4eb07c2115b713b2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3f6f3e91f348fca9e22f67bdd97613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b6516de9b7d46bfb723bbba90e3de0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a157069cca0e42fb87fdca4f1cdddbda",
            "placeholder": "​",
            "style": "IPY_MODEL_965c42e01943456dae8e71271b21a3d9",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 6.40MB/s]"
          }
        },
        "91e2a189eb864017bdef9a6c4745ef92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a0f761ea73b40f3a104375380d51577",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fdf3ccba6d44a7a8a7d9a835fdbd90c",
            "value": 3
          }
        },
        "95757e0c687c44ebaf301c4ad7bc7442": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965c42e01943456dae8e71271b21a3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee6f1579912480cb620ef20ecd6c49b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fdf3ccba6d44a7a8a7d9a835fdbd90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a057909f7c754f0bbbc2d2c3d0322956": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a138eb8afdfc44c780b9b9278e54a8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a157069cca0e42fb87fdca4f1cdddbda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34a9e1c71e640ed9d5baea711387937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a057909f7c754f0bbbc2d2c3d0322956",
            "placeholder": "​",
            "style": "IPY_MODEL_2c5e727c5be847e9890f2acf2cf80719",
            "value": "tokenizer.model: 100%"
          }
        },
        "a421692915784383a4e87d909134266c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b6782416ca47a7be54d10230b10c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479d18aabb8b49ee8fa3755419da21ca",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af3087604ac468396c6a27b339620a0",
            "value": 4689074
          }
        },
        "ab8aea5172f947b1b0eb8e09f31020d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31091df2baa74885a4f1870366232d6c",
            "max": 1156999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8015f10bad5f4947a4b4b41c85b84062",
            "value": 1156999
          }
        },
        "aea4eadbe6ed45938ffe0d04ba7d41f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55331ba2c354aa8891ad6cbeb01592f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3118c66e3564a699ac2d3dbed2ecee9",
              "IPY_MODEL_c32612a157d84147af4992619de256b6",
              "IPY_MODEL_f04a8192e5114c47948a09cb4837530b"
            ],
            "layout": "IPY_MODEL_2e7f41bc08f34447b921573ee64bf27b"
          }
        },
        "b7f0d74241ae49ce98b627e5181419c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce71b33f77341a4a7938e8741a8bc66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32612a157d84147af4992619de256b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ae8717028c4e44a5dcb9dfb454c3cb",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_690aceaa89ed4160a07a105acf2b6447",
            "value": 33384568
          }
        },
        "c941b50f564d4f3f9281fe4269fbb176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e190c6eed0a44deebe760cfa25d117e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a34a9e1c71e640ed9d5baea711387937",
              "IPY_MODEL_a5b6782416ca47a7be54d10230b10c08",
              "IPY_MODEL_432e7e26e2d145cda0a952b58408c929"
            ],
            "layout": "IPY_MODEL_eabf729c3c244e0896800f99b878a1fd"
          }
        },
        "e3142df156bb49efa81cdce010d651e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabf729c3c244e0896800f99b878a1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04a8192e5114c47948a09cb4837530b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143e7e3f017f494db7af5f182e4f9e95",
            "placeholder": "​",
            "style": "IPY_MODEL_85b2dcbecce94d4eb07c2115b713b2b5",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 162MB/s]"
          }
        },
        "f30ca15a1d0b432881a3850690553ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3118c66e3564a699ac2d3dbed2ecee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34aa0e48509d422f8b29c88a73d787c1",
            "placeholder": "​",
            "style": "IPY_MODEL_239a40fc59504cd89a545e4d30812fd1",
            "value": "tokenizer.json: 100%"
          }
        },
        "f5929f6ac17f418c985a9436876807e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f0d74241ae49ce98b627e5181419c3",
            "placeholder": "​",
            "style": "IPY_MODEL_aea4eadbe6ed45938ffe0d04ba7d41f4",
            "value": " 3/3 [01:23&lt;00:00, 27.62s/it]"
          }
        },
        "ff786f9f66ea43adbac990c21642f0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
